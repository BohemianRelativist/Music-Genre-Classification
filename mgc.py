# -*- coding: utf-8 -*-
"""MGC.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BNeI8hauuMyFa4OLDTJ7B8_eujQrGRUn

# Loading Data
"""

!wget 'https://osf.io/drjhb/download'
!unzip '/content/download'

"""# Importing Libraries"""

import os
import matplotlib.pyplot as plt
import torch
import torchaudio
import torch.nn as nn
import gc
import torch.nn.functional as F
from torchvision.datasets import ImageFolder
import torchvision.transforms as transforms
from torch.utils.data import DataLoader

"""Checking for CPU"""

if torch.cuda.is_available():
  dev = "cuda:0"
else:
  dev = "cpu"
device = torch.device(dev)
print(f"Using {device} device")
print(torch.cuda.get_device_name(torch.cuda.current_device()))

"""#Making Spectrogram and Saving them

```
`# This is formatted as code`
```


"""

def plot_specgram(waveform, sample_rate, title="Spectrogram"):
    waveform = waveform.numpy()

    num_channels, num_frames = waveform.shape

    figure, axes = plt.subplots(num_channels, 1)
    if num_channels == 1:
        axes = [axes]
    for c in range(num_channels):
        axes[c].specgram(waveform[c], Fs=sample_rate)
        if num_channels > 1:
            axes[c].set_ylabel(f"Channel {c+1}")
    #figure.suptitle(title)
    #plt.show(block=False)

path = '/content/SpecGram'
if not os.path.exists(path):
  os.makedirs(path)
if not os.path.exists('/content/Test'):
  os.makedirs('/content/Test')

l=['blues','classical','country','disco','hiphop','jazz','metal','pop','reggae','rock']
for i in range(len(l)):
  h=0
  os.makedirs('/content/SpecGram/'+l[i])      #For train set
  os.makedirs('/content/Test/'+l[i])          #For test set
  for filename in os.scandir('/content/Data/genres_original/'+ l[i]):
    try:
      waveform,time=torchaudio.load(filename) 
      plot_specgram(waveform,time)
      h=h+1
      if h<=90: 
        # Making a train set of 90 images from each genre      
        plt.savefig('/content/SpecGram/'+l[i]+'/'+l[i]+str(h)+'.png')
        plt.close()
      else:
        # Making a test set of 10 images from each genre
        plt.savefig('/content/Test/'+l[i]+'/'+l[i]+str(h)+'.png')
        plt.close()
    except:
      RuntimeError

"""#Neural Network"""

class Net(nn.Module):

  def __init__(self):
    super(Net,self).__init__()
    self.C1=nn.Sequential(
            nn.Conv2d(3,16,kernel_size=7,stride=1,padding=3),
            nn.BatchNorm2d(16),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2)
    )
    self.C2=nn.Sequential(
            nn.Conv2d(16,32,kernel_size=5,stride=1,padding=2),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2,stride=2)
        
    )
    self.C3=nn.Sequential(
            nn.Conv2d(32,64,kernel_size=3,stride=1,padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2,stride=2)
    )
    self.L1=nn.Linear(32*32*64,4096)
    self.L2=nn.Linear(4096,2048)
    self.L3=nn.Linear(2048,512)
    self.L4=nn.Linear(512,10)

  def forward(self, x):
    x=self.C1(x)
    x=self.C2(x)
    x=self.C3(x)
    x=x.reshape(x.size(0),-1)
    x=F.relu(self.L1(x))
    x=F.relu(self.L2(x))
    x=F.relu(self.L3(x))
    x=(self.L4(x))
    return F.log_softmax(x)

net=Net()
net = net.to(device)
optimizer = torch.optim.Adam(net.parameters(), lr=0.0015)
criterion = nn.CrossEntropyLoss()
loss_fn=nn.CrossEntropyLoss()

"""#Dataloader"""

tran = transforms.Compose([transforms.ToTensor(), transforms.Resize((256,256))]) #Resized the original spectrogram to (256,256)
data_set = ImageFolder('/content/SpecGram', transform = tran)
data =DataLoader(data_set, batch_size =64, shuffle=True)

epoch=1

"""#Training the Network"""

l=[]
accuracy=[]
e=[]

for j in range(epoch):
  #to delete variables not in use
  torch.cuda.empty_cache()                              
  gc.collect()
  for i, (img,lbl) in enumerate(data):   
    #moving the data to GPU             
    img = img.to(device)
    lbl = lbl.to(device)
    #NN output
    out=net(img)
    #calculating Accuracy and Loss
    loss=loss_fn(out,lbl)
    l.append(float(loss))
    total=lbl.size(0)
    _, predicted = torch.max(out.data , 1)
    correct = (predicted == lbl).sum().item()
    acc = correct*100/total
    accuracy.append(acc)
    if i%10 == 0:
      print(loss)
      print(acc)
    #Gradient Descent  
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

plt.plot(accuracy)
plt.title("Accuracy")

plt.plot(l)
plt.title('Loss')
plt.show()

